{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MNIST with ConvNets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import absolute_import, division, print_function \n",
    "\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import os\n",
    "import sys\n",
    "sys.path.append(os.path.join('.', '..')) \n",
    "import utils \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The MNIST data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting MNIST_data/train-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/train-labels-idx1-ubyte.gz\n",
      "Extracting MNIST_data/t10k-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/t10k-labels-idx1-ubyte.gz\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Load data\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "mnist_data = input_data.read_data_sets('MNIST_data', \n",
    "                                       one_hot=True,   # Convert the labels into one hot encoding\n",
    "                                       dtype='float32', # rescale images to `[0, 1]`\n",
    "                                       reshape=False, # Don't flatten the images to vectors\n",
    "                                      )\n",
    "\n",
    "## Print dataset statistics and visualize\n",
    "print('')\n",
    "utils.mnist_summary(mnist_data)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "from keras.layers import Input, Dense, Conv2D, MaxPooling2D\n",
    "from tensorflow.contrib.layers import flatten"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trace of the tensors shape as it is propagated through the network.\n",
      "Layer name \t Output size\n",
      "----------------------------\n",
      "x_pl \t\t (?, 28, 28, 1)\n",
      "conv1 \t\t (?, 28, 28, 4)\n",
      "pool1 \t\t (?, 14, 14, 4)\n",
      "conv2 \t\t (?, 14, 14, 2)\n",
      "pool2 \t\t (?, 7, 7, 2)\n",
      "Flatten \t (?, 98)\n",
      "denseOut\t (?, 10)\n"
     ]
    }
   ],
   "source": [
    "tf.reset_default_graph()\n",
    "\n",
    "num_classes = 10\n",
    "height, width, nchannels = 28, 28, 1\n",
    "padding = 'same'\n",
    "\n",
    "filters_1 = 4\n",
    "kernel_size_1 = (5,5)\n",
    "pool_size_1 = (2,2)\n",
    "\n",
    "filters_2 = 2\n",
    "kernel_size_2 = (3,3)\n",
    "pool_size_2 = (2,2)\n",
    "\n",
    "x_pl = tf.placeholder(tf.float32, [None, height, width, nchannels], name='xPlaceholder')\n",
    "y_pl = tf.placeholder(tf.float64, [None, num_classes], name='yPlaceholder')\n",
    "y_pl = tf.cast(y_pl, tf.float32)\n",
    "\n",
    "print('Trace of the tensors shape as it is propagated through the network.')\n",
    "print('Layer name \\t Output size')\n",
    "print('----------------------------')\n",
    "\n",
    "with tf.variable_scope('convLayer1'):\n",
    "    conv1 = Conv2D(filters_1, kernel_size_1, strides=(1,1), padding=padding, activation='relu')\n",
    "    print('x_pl \\t\\t', x_pl.get_shape())\n",
    "    x = conv1(x_pl)\n",
    "    print('conv1 \\t\\t', x.get_shape())\n",
    "\n",
    "    pool1 = MaxPooling2D(pool_size=pool_size_1, strides=None, padding=padding)\n",
    "    x = pool1(x)\n",
    "    print('pool1 \\t\\t', x.get_shape())\n",
    "    \n",
    "with tf.variable_scope('convLayer2'):\n",
    "    conv2 = Conv2D(filters_2, kernel_size_2, strides=(1,1), padding=padding, activation='relu')\n",
    "    x = conv2(x)\n",
    "    print('conv2 \\t\\t', x.get_shape())\n",
    "\n",
    "    pool2 = MaxPooling2D(pool_size=pool_size_2, strides=None, padding=padding)\n",
    "    x = pool2(x)\n",
    "    print('pool2 \\t\\t', x.get_shape())\n",
    "    x = flatten(x)\n",
    "    print('Flatten \\t', x.get_shape())\n",
    "\n",
    "with tf.variable_scope('output_layer'):\n",
    "    denseOut = Dense(units=num_classes, activation='softmax')\n",
    "    \n",
    "    y = denseOut(x)\n",
    "    print('denseOut\\t', y.get_shape())    \n",
    "\n",
    "print('Model consits of ', utils.num_params(), 'trainable parameters.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trace of the tensors shape as it is propagated through the network.\n",
      "Layer name \t Output size\n",
      "----------------------------\n",
      "x_pl \t\t (?, 28, 28, 1)\n",
      "flatten \t (?, 784)\n",
      "dense1 \t\t (?, 2)\n",
      "denseOut\t (?, 10)\n",
      "Model consits of  1600 trainable parameters.\n"
     ]
    }
   ],
   "source": [
    "# this is the network for exe 1.4\n",
    "\n",
    "tf.reset_default_graph()\n",
    "\n",
    "num_classes = 10\n",
    "height, width, nchannels = 28, 28, 1\n",
    "\n",
    "dense_size_1 = 2\n",
    "\n",
    "x_pl = tf.placeholder(tf.float32, [None, height, width, nchannels], name='xPlaceholder')\n",
    "y_pl = tf.placeholder(tf.float64, [None, num_classes], name='yPlaceholder')\n",
    "y_pl = tf.cast(y_pl, tf.float32)\n",
    "\n",
    "print('Trace of the tensors shape as it is propagated through the network.')\n",
    "print('Layer name \\t Output size')\n",
    "print('----------------------------')\n",
    "\n",
    "with tf.variable_scope('denseLayer1'):\n",
    "    x = flatten(x_pl)\n",
    "    print('x_pl \\t\\t', x_pl.get_shape())\n",
    "    dense1 = Dense(units=dense_size_1, activation='relu')\n",
    "    print('flatten \\t', x.get_shape())\n",
    "    x = dense1(x)\n",
    "    print('dense1 \\t\\t', x.get_shape())\n",
    "\n",
    "with tf.variable_scope('output_layer'):\n",
    "    denseOut = Dense(units=num_classes, activation='softmax')\n",
    "    \n",
    "    y = denseOut(x)\n",
    "    print('denseOut\\t', y.get_shape())    \n",
    "\n",
    "print('Model consits of ', utils.num_params(), 'trainable parameters.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "with tf.variable_scope('loss'):\n",
    "    # computing cross entropy per sample\n",
    "    cross_entropy = -tf.reduce_sum(y_pl * tf.log(y+1e-8), reduction_indices=[1])\n",
    "\n",
    "    # averaging over samples\n",
    "    cross_entropy = tf.reduce_mean(cross_entropy)\n",
    "\n",
    "    \n",
    "with tf.variable_scope('training'):\n",
    "    # defining our optimizer\n",
    "    optimizer = tf.train.AdamOptimizer(learning_rate=0.001)\n",
    "\n",
    "    # applying the gradients\n",
    "    train_op = optimizer.minimize(cross_entropy)\n",
    "\n",
    "    \n",
    "with tf.variable_scope('performance'):\n",
    "    # making a one-hot encoded vector of correct (1) and incorrect (0) predictions\n",
    "    correct_prediction = tf.equal(tf.argmax(y, axis=1), tf.argmax(y_pl, axis=1))\n",
    "\n",
    "    # averaging the one-hot encoded vector\n",
    "    accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Forward pass successful!\n"
     ]
    }
   ],
   "source": [
    "#Test the forward pass\n",
    "x_batch, y_batch = mnist_data.train.next_batch(4)\n",
    "\n",
    "with tf.Session(config=tf.ConfigProto(gpu_options=gpu_opts)) as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    y_pred = sess.run(fetches=y, feed_dict={x_pl: x_batch})\n",
    "\n",
    "assert y_pred.shape == y_batch.shape, \"ERROR the output shape is not as expected!\" \\\n",
    "        + \" Output shape should be \" + str(y.shape) + ' but was ' + str(y_pred.shape)\n",
    "\n",
    "print('Forward pass successful!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Begin training loop\n",
      "Epoch 1 : Train Loss  0.183, Train acc  0.950,  Valid loss  0.159,  Valid acc  0.956\n",
      "Epoch 2 : Train Loss  0.082, Train acc  0.970,  Valid loss  0.096,  Valid acc  0.973\n",
      "Epoch 3 : Train Loss  0.140, Train acc  0.970,  Valid loss  0.073,  Valid acc  0.979\n",
      "Epoch 4 : Train Loss  0.040, Train acc  0.990,  Valid loss  0.062,  Valid acc  0.981\n",
      "Epoch 5 : Train Loss  0.059, Train acc  0.970,  Valid loss  0.060,  Valid acc  0.981\n",
      "Epoch 6 : Train Loss  0.012, Train acc  1.000,  Valid loss  0.063,  Valid acc  0.980\n",
      "Epoch 7 : Train Loss  0.051, Train acc  0.990,  Valid loss  0.053,  Valid acc  0.983\n",
      "Epoch 8 : Train Loss  0.021, Train acc  1.000,  Valid loss  0.053,  Valid acc  0.984\n",
      "Epoch 9 : Train Loss  0.066, Train acc  0.990,  Valid loss  0.056,  Valid acc  0.982\n",
      "Epoch 10 : Train Loss  0.048, Train acc  0.990,  Valid loss  0.055,  Valid acc  0.984\n",
      "Test Loss  0.050, Test acc  0.984\n"
     ]
    }
   ],
   "source": [
    "#Training Loop\n",
    "batch_size = 100\n",
    "max_epochs = 10\n",
    "\n",
    "\n",
    "valid_loss, valid_accuracy = [], []\n",
    "train_loss, train_accuracy = [], []\n",
    "test_loss, test_accuracy = [], []\n",
    "\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    print('Begin training loop')\n",
    "\n",
    "    try:\n",
    "        while mnist_data.train.epochs_completed < max_epochs:\n",
    "            _train_loss, _train_accuracy = [], []\n",
    "            \n",
    "            ## Run train op\n",
    "            x_batch, y_batch = mnist_data.train.next_batch(batch_size)\n",
    "            fetches_train = [train_op, cross_entropy, accuracy]\n",
    "            feed_dict_train = {x_pl: x_batch, y_pl: y_batch}\n",
    "            _, _loss, _acc = sess.run(fetches_train, feed_dict_train)\n",
    "            \n",
    "            _train_loss.append(_loss)\n",
    "            _train_accuracy.append(_acc)\n",
    "            \n",
    "\n",
    "            ## Compute validation loss and accuracy\n",
    "            if mnist_data.train.epochs_completed % 1 == 0 \\\n",
    "                    and mnist_data.train._index_in_epoch <= batch_size:\n",
    "                train_loss.append(np.mean(_train_loss))\n",
    "                train_accuracy.append(np.mean(_train_accuracy))\n",
    "\n",
    "                fetches_valid = [cross_entropy, accuracy]\n",
    "                \n",
    "                feed_dict_valid = {x_pl: mnist_data.validation.images, y_pl: mnist_data.validation.labels}\n",
    "                _loss, _acc = sess.run(fetches_valid, feed_dict_valid)\n",
    "                \n",
    "                valid_loss.append(_loss)\n",
    "                valid_accuracy.append(_acc)\n",
    "                print(\"Epoch {} : Train Loss {:6.3f}, Train acc {:6.3f},  Valid loss {:6.3f},  Valid acc {:6.3f}\".format(\n",
    "                    mnist_data.train.epochs_completed, train_loss[-1], train_accuracy[-1], valid_loss[-1], valid_accuracy[-1]))\n",
    "        \n",
    "        \n",
    "        test_epoch = mnist_data.test.epochs_completed\n",
    "        while mnist_data.test.epochs_completed == test_epoch:\n",
    "            x_batch, y_batch = mnist_data.test.next_batch(batch_size)\n",
    "            feed_dict_test = {x_pl: x_batch, y_pl: y_batch}\n",
    "            _loss, _acc = sess.run(fetches_valid, feed_dict_test)\n",
    "            test_loss.append(_loss)\n",
    "            test_accuracy.append(_acc)\n",
    "        print('Test Loss {:6.3f}, Test acc {:6.3f}'.format(\n",
    "                    np.mean(test_loss), np.mean(test_accuracy)))\n",
    "\n",
    "\n",
    "    except KeyboardInterrupt:\n",
    "        pass\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<matplotlib.text.Text at 0x7f3e459e9f98>,\n",
       " <matplotlib.text.Text at 0x7f3e4578f048>,\n",
       " (0.75, 1.03))"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYsAAAEKCAYAAADjDHn2AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f3ea2cdd898>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "epoch = np.arange(len(train_loss))\n",
    "plt.figure()\n",
    "plt.plot(epoch, train_accuracy,'r', epoch, valid_accuracy,'b')\n",
    "plt.legend(['Train Acc','Val Acc'], loc=4)\n",
    "plt.xlabel('Epochs'), plt.ylabel('Acc'), plt.ylim([0.75,1.03])"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
